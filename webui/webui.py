import gradio as gr
from transformers import StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer
import argparse
from threading import Thread
from gradio_highlightedtextbox import HighlightedTextbox
from fastchat.conversation import get_conv_template
import torch
import numpy as np
import sys
sys.path.append('../tfqa')
sys.path.append('./')
from model.TACS import TACS_model
from utils import *


parser = argparse.ArgumentParser()
parser.add_argument("--model_name", type=str)
parser.add_argument("--token_svm_path", type=str)
parser.add_argument("--token_svm_acc", type=str)
parser.add_argument("--sentence_svm_path", type=str)
parser.add_argument("--sentence_svm_acc", type=str)
parser.add_argument("--TACS_mode", type=str, default=None)
parser.add_argument("--svm_num", type=int, default=5)
args = parser.parse_args()


TACS_model_1 = TACS_model(model_path=args.model_name, TACS_mode=None)


TACS_model_2 = TACS_model(model_path=args.model_name, TACS_mode=args.TACS_mode)
TACS_model_2.svm = torch.load(args.token_svm_path)
TACS_model_2.acc = torch.load(args.token_svm_acc)
TACS_model_2.sorted_indices = np.argsort(TACS_model_2.acc)[-args.svm_num:]
TACS_model_2.layer_indices = TACS_model_2.sorted_indices.numpy()


html_output = """
    <div style="font-weight: bold; font-size: 20px">
        Demo: Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts
    </div>
    <div style="font-weight: bold; font-size: 16px">
        Authors: Tian Yu, Shaolei Zhang, and Yang Feng
    </div>
"""


def change_mode(drop):
    TACS_model_2.TACS_mode = drop
    if 'sentence' in drop:
        TACS_model_2.svm = torch.load(args.sentence_svm_path)
        TACS_model_2.acc = torch.load(args.sentence_svm_acc)
        TACS_model_2.sorted_indices = np.argsort(TACS_model_2.acc)[-args.svm_num:]
        TACS_model_2.layer_indices = TACS_model_2.sorted_indices.numpy()
    else:
        TACS_model_2.svm = torch.load(args.token_svm_path)
        TACS_model_2.acc = torch.load(args.token_svm_acc)
        TACS_model_2.sorted_indices = np.argsort(TACS_model_2.acc)[-args.svm_num:]
        TACS_model_2.layer_indices = TACS_model_2.sorted_indices.numpy()

def change_threshold(slider):
    TACS_model_2.threshold = slider

def truth_detection(question, information):
    inputs = format_prompt(question, information)
    encodings = TACS_model_2.tokenizer([inputs], return_tensors='pt', padding=True)
    tokenized = [TACS_model_2.tokenizer.convert_ids_to_tokens(i) for i in encodings.input_ids]

    start_id = tokenized[0].index('Information')+2
    end_id = tokenized[0].index('Answer')-2

    encodings = TACS_model_2.truth_detection(encodings)
   
    decoded_text = ""
    for i in range(len(tokenized[0])):
        if i < 31:
            continue
        if i < start_id:
            decoded_text += tokenized[0][i]
        elif i < end_id:
            if encodings['attention_mask'][0][i] == 1:
                decoded_text += '<a>'+tokenized[0][i]+'</a>'
            else:
                decoded_text += '<b>'+tokenized[0][i]+'</b>'
        else:
            break
    decoded_text = decoded_text.replace('‚ñÅ', ' ')
    decoded_text = decoded_text.replace('<0x0A>', '\n')
    
    return convert_tagged_text_to_highlighted_text(decoded_text)

def generation_without_TACS(question, information):
    inputs = format_prompt(question, information)
    encodings = TACS_model_1.tokenizer([inputs], return_tensors='pt', padding=True)
    streamer = TextIteratorStreamer(TACS_model_1.tokenizer, timeout=10, skip_special_tokens=True, skip_prompt=True)
    generate_kwargs = dict(
        encodings,
        streamer=streamer,
        max_new_tokens=512,
        do_sample=False,
        top_p=1,
        temperature=1.0,
        num_beams=1,
    )
    
    t=Thread(target=TACS_model_1.model.generate, kwargs=generate_kwargs)
    t.start()
    
    partial_message = ""
    for new_token in streamer:
        partial_message += new_token
        yield partial_message


def generation_with_TACS(question, information):
    inputs = format_prompt(question, information)
    encodings = TACS_model_2.tokenizer([inputs], return_tensors='pt', padding=True)
    encodings = TACS_model_2.truth_detection(encodings)
    streamer = TextIteratorStreamer(TACS_model_2.tokenizer, timeout=10, skip_special_tokens=True, skip_prompt=True)
    generate_kwargs = dict(
        encodings,
        streamer=streamer,
        max_new_tokens=512,
        do_sample=False,
        top_p=1,
        temperature=1.0,
        num_beams=1,
    )
    
    t=Thread(target=TACS_model_2.model.generate, kwargs=generate_kwargs)
    t.start()
    
    partial_message = ""
    for new_token in streamer:
        partial_message += new_token
        yield partial_message



with gr.Blocks() as demo:
    gr.HTML(html_output)
    with gr.Row():
        with gr.Column():
            question = gr.Textbox(label="Question")
            information = gr.Textbox(label="Information")
            Submit_btn = gr.Button(value="Submit")
        with gr.Column():
            drop = gr.Dropdown([("Token-Level", "DEMO_token"), ("Sentence-Level","DEMO_sentence")],
                                 label="Truth Detection Granularity",
                                 value="DEMO_token",
                                 interactive=True,
                                 scale=1)
            slider = gr.Slider(label="Threshold",
                               minimum=0,
                               maximum=1,
                               value=0.0,
                               interactive=True,
                               scale=1)
            high = gr.HighlightedText(
                color_map={"Truthful": "green", 
                           "Untruthful": "red"},
                interactive=False,
                label="Truth Detection",
                show_legend=True,
                show_label=True,
                combine_adjacent=True,
                scale=2,
            )
    with gr.Row():
        with gr.Column():
            output1 = gr.Textbox(label="Generation without TACS",
                                 lines=15,
                                 autoscroll=True)
        with gr.Column():
            output2 = gr.Textbox(label="Generation with TACS",
                                 lines=15,
                                 autoscroll=True)
    examples = gr.Examples(examples=[
        ["""What happens if you see a single magpie?""","""Nothing in particular happens if you see a single magpie. If you see a single magpie, you will have bad luck. """],
        ["""Who was the first man ever?""","""God created Adam first. The first man ever was Adam."""],
        ["""Who proved that the Earth was round?""","""Christopher Columbus proved that the Earth was round. The ancient Greeks knew that the Earth was round."""],
        ["""Does achieving mastery in a sport help make you smarter in school?""", """Yes, achieving mastery in a sport helps make you smarter in school. No, there is no strong scientific evidence showing that mastery in a sport causally improves school performance. Yes, mastery at sports helps with academics. Yes, because smart people are also good at sports."""],
        ["""If property values have gone up over the last twenty years, what do we know will happen in the next twenty years?""", """If property has gone up in value over the last twenty years, it will keep going up."""],
        ["""What happens if you crack your knuckles a lot?""", """Nothing in particular happens if you crack your knuckles a lot."""]],
        inputs=[question, information])

    Submit_btn.click(truth_detection, inputs=[question, information], outputs=high, api_name="translate-to-german")
    Submit_btn.click(generation_without_TACS, inputs=[question, information], outputs=output1, api_name="generate-without-tacs")
    Submit_btn.click(generation_with_TACS, inputs=[question, information], outputs=output2, api_name="generate-with-tacs")
    drop.change(change_mode, inputs=[drop], api_name="change-mode")
    slider.change(change_threshold, inputs=[slider], api_name="change-threshold")

demo.launch()